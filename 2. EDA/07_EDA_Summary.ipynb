{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# EDA Summary & Key Findings\n",
        "\n",
        "**Purpose:** Consolidate key insights from all EDA notebooks for project discussion and presentation.\n",
        "\n",
        "**Notebooks Reviewed:**\n",
        "1. Data Exploration\n",
        "2. Data Quality\n",
        "3. Univariate Analysis\n",
        "4. Bivariate Analysis\n",
        "5. Outlier Analysis\n",
        "6. Multivariate Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sqlite3\n",
        "\n",
        "# Visualization settings\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['font.size'] = 12\n",
        "pd.set_option('display.max_columns', None)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "conn = sqlite3.connect('../databases/nhanes_1st.db')\n",
        "df = pd.read_sql_query('SELECT * FROM raw_dataset', conn)\n",
        "conn.close()\n",
        "\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(f\"Total records: {len(df):,}\")\n",
        "print(f\"Total features: {df.shape[1]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Dataset Overview\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*80)\n",
        "print(\"DATASET OVERVIEW\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nTotal Records: {len(df):,}\")\n",
        "print(f\"Total Features: {df.shape[1]}\")\n",
        "print(f\"\\nFeature Categories:\")\n",
        "print(f\"  - Demographics: age, gender, ethnicity, income_ratio\")\n",
        "print(f\"  - Physical Measurements: BMI, height, heart_rate\")\n",
        "print(f\"  - Blood Tests: WBC, platelets, hemoglobin, MCV\")\n",
        "print(f\"  - Kidney Markers: creatinine, uric_acid\")\n",
        "print(f\"  - Liver Markers: AST, bilirubin, GGT, ALT\")\n",
        "print(f\"  - Electrolytes: sodium, potassium\")\n",
        "print(f\"  - Lipids: cholesterol\")\n",
        "print(f\"  - Lifestyle: alcohol, smoking\")\n",
        "print(f\"  - Target Variables: 4 tasks (CVD, Metabolic, Kidney, Liver)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Quality Summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Missing values summary\n",
        "missing = df.isnull().sum()\n",
        "missing_pct = (missing / len(df)) * 100\n",
        "missing_df = pd.DataFrame({'Missing': missing, 'Percent': missing_pct})\n",
        "missing_df = missing_df[missing_df['Missing'] > 0].sort_values('Percent', ascending=False)\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"DATA QUALITY SUMMARY\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nColumns with missing values: {len(missing_df)}\")\n",
        "print(f\"\\nTop 10 columns with highest missing rates:\")\n",
        "print(missing_df.head(10).to_string())\n",
        "\n",
        "high_missing = missing_df[missing_df['Percent'] > 50]\n",
        "print(f\"\\n⚠️ Columns with >50% missing: {len(high_missing)}\")\n",
        "if len(high_missing) > 0:\n",
        "    print(high_missing.to_string())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Target Variables Analysis (All 4 Tasks)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Task A: Cardiovascular Disease\n",
        "print(\"=\"*80)\n",
        "print(\"TASK A: CARDIOVASCULAR DISEASE\")\n",
        "print(\"=\"*80)\n",
        "if 'has_cardiovascular_disease' in df.columns:\n",
        "    cardio_counts = df['has_cardiovascular_disease'].value_counts(dropna=False)\n",
        "    cardio_pct = df['has_cardiovascular_disease'].value_counts(normalize=True, dropna=False) * 100\n",
        "    print(f\"\\nDistribution:\")\n",
        "    print(f\"  Healthy (0): {cardio_counts.get(0, 0):,} ({cardio_pct.get(0, 0):.2f}%)\")\n",
        "    print(f\"  Has CVD (1): {cardio_counts.get(1, 0):,} ({cardio_pct.get(1, 0):.2f}%)\")\n",
        "    print(f\"  Missing: {df['has_cardiovascular_disease'].isnull().sum():,}\")\n",
        "    \n",
        "    plt.figure(figsize=(8, 5))\n",
        "    cardio_counts.plot(kind='bar', color=['skyblue', 'coral'])\n",
        "    plt.title('Cardiovascular Disease Distribution')\n",
        "    plt.xlabel('CVD Status')\n",
        "    plt.ylabel('Count')\n",
        "    plt.xticks([0, 1], ['Healthy', 'Has CVD'], rotation=0)\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Task B: Metabolic Syndrome Components\n",
        "print(\"=\"*80)\n",
        "print(\"TASK B: METABOLIC SYNDROME COMPONENTS (5 Labels)\")\n",
        "print(\"=\"*80)\n",
        "metabolic_labels = [\n",
        "    'high_waist_circumference',\n",
        "    'high_triglycerides_mg_dl',\n",
        "    'low_hdl_mg_dl',\n",
        "    'high_blood_pressure',\n",
        "    'high_glucose_mg_dl'\n",
        "]\n",
        "\n",
        "for label in metabolic_labels:\n",
        "    if label in df.columns:\n",
        "        counts = df[label].value_counts(dropna=False)\n",
        "        pct = df[label].value_counts(normalize=True, dropna=False) * 100\n",
        "        missing = df[label].isnull().sum()\n",
        "        print(f\"\\n{label}:\")\n",
        "        print(f\"  Normal (0): {counts.get(0, 0):,} ({pct.get(0, 0):.2f}%)\")\n",
        "        print(f\"  Abnormal (1): {counts.get(1, 0):,} ({pct.get(1, 0):.2f}%)\")\n",
        "        print(f\"  Missing: {missing:,} ({missing/len(df)*100:.2f}%)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Task C: Kidney Function (ACR Log)\n",
        "print(\"=\"*80)\n",
        "print(\"TASK C: KIDNEY FUNCTION (ACR Log)\")\n",
        "print(\"=\"*80)\n",
        "if 'kidney_acr_mg_g' in df.columns:\n",
        "    kidney_data = df['kidney_acr_mg_g'].dropna()\n",
        "    print(f\"\\nStatistics:\")\n",
        "    print(f\"  Mean: {kidney_data.mean():.4f}\")\n",
        "    print(f\"  Median: {kidney_data.median():.4f}\")\n",
        "    print(f\"  Std: {kidney_data.std():.4f}\")\n",
        "    print(f\"  Min: {kidney_data.min():.4f}\")\n",
        "    print(f\"  Max: {kidney_data.max():.4f}\")\n",
        "    print(f\"  Missing: {df['kidney_acr_mg_g'].isnull().sum():,} ({df['kidney_acr_mg_g'].isnull().sum()/len(df)*100:.2f}%)\")\n",
        "    \n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.hist(kidney_data, bins=50, color='steelblue', alpha=0.7, edgecolor='black')\n",
        "    plt.axvline(kidney_data.mean(), color='red', linestyle='--', label=f'Mean: {kidney_data.mean():.2f}')\n",
        "    plt.axvline(kidney_data.median(), color='green', linestyle='-', label=f'Median: {kidney_data.median():.2f}')\n",
        "    plt.title('Kidney Function (ACR Log) Distribution')\n",
        "    plt.xlabel('ACR (Log Scale)')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.legend()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Task D: Liver Function (ALT Log)\n",
        "print(\"=\"*80)\n",
        "print(\"TASK D: LIVER FUNCTION (ALT Log)\")\n",
        "print(\"=\"*80)\n",
        "if 'liver_alt_U_L' in df.columns:\n",
        "    liver_data = df['liver_alt_U_L'].dropna()\n",
        "    print(f\"\\nStatistics:\")\n",
        "    print(f\"  Mean: {liver_data.mean():.4f}\")\n",
        "    print(f\"  Median: {liver_data.median():.4f}\")\n",
        "    print(f\"  Std: {liver_data.std():.4f}\")\n",
        "    print(f\"  Min: {liver_data.min():.4f}\")\n",
        "    print(f\"  Max: {liver_data.max():.4f}\")\n",
        "    print(f\"  Missing: {df['liver_alt_U_L'].isnull().sum():,} ({df['liver_alt_U_L'].isnull().sum()/len(df)*100:.2f}%)\")\n",
        "    \n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.hist(liver_data, bins=50, color='coral', alpha=0.7, edgecolor='black')\n",
        "    plt.axvline(liver_data.mean(), color='red', linestyle='--', label=f'Mean: {liver_data.mean():.2f}')\n",
        "    plt.axvline(liver_data.median(), color='green', linestyle='-', label=f'Median: {liver_data.median():.2f}')\n",
        "    plt.title('Liver Function (ALT Log) Distribution')\n",
        "    plt.xlabel('ALT (Log Scale)')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.legend()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Key Findings & Insights\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.1 Data Quality Findings\n",
        "\n",
        "1. **Missing Data:**\n",
        "   - 4 columns have >50% missing values (smoking_status, high_glucose_mg_dl, high_triglycerides_mg_dl, alcohol_drinks_per_week)\n",
        "   - Most clinical markers have 30-40% missing values\n",
        "   - Missing data is handled via masking in the model\n",
        "\n",
        "2. **Data Quality:**\n",
        "   - Some impossible values detected (e.g., WBC >50, platelets outside normal range)\n",
        "   - 20,489 duplicate rows found\n",
        "   - Most outliers are medically valid (represent real medical conditions)\n",
        "\n",
        "### 4.2 Target Variable Insights\n",
        "\n",
        "1. **Cardiovascular Disease:**\n",
        "   - Class imbalance present (needs to be addressed in training)\n",
        "   - Missing values: ~40% of records\n",
        "\n",
        "2. **Metabolic Syndrome:**\n",
        "   - 5 binary labels (multi-label classification)\n",
        "   - High missing rates for some components (glucose, triglycerides)\n",
        "   - Each component can be analyzed independently\n",
        "\n",
        "3. **Kidney & Liver Function:**\n",
        "   - Regression tasks on log-transformed values\n",
        "   - Right-skewed distributions (log transformation appropriate)\n",
        "   - Missing values: ~20-40% of records\n",
        "\n",
        "### 4.3 Feature Relationships\n",
        "\n",
        "1. **High Correlations Found:**\n",
        "   - Age ↔ Height (0.532)\n",
        "   - Height ↔ BMI (0.494)\n",
        "   - Liver AST ↔ Liver GGT (0.399)\n",
        "\n",
        "2. **Clinical Insights:**\n",
        "   - Age is a key factor for multiple conditions\n",
        "   - Liver markers are correlated (expected clinically)\n",
        "   - Physical measurements (height, BMI) are related\n",
        "\n",
        "### 4.4 Outlier Analysis\n",
        "\n",
        "1. **Outlier Detection:**\n",
        "   - Z-score method: 6,859 outliers detected\n",
        "   - IQR method: 26,228 outliers detected\n",
        "   - Most outliers are medically valid\n",
        "\n",
        "2. **Variables Needing Review:**\n",
        "   - White blood cells count\n",
        "   - Platelets count\n",
        "   - Sodium\n",
        "   - Potassium\n",
        "   - Alcohol consumption\n",
        "\n",
        "3. **Recommendations:**\n",
        "   - Keep outliers for most variables (medically valid)\n",
        "   - Use robust scaling methods\n",
        "   - Consider log transformation for highly skewed variables\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.1 Data Preprocessing\n",
        "\n",
        "1. **Handle Missing Values:**\n",
        "   - Use masking approach (already implemented in dataset.py)\n",
        "   - Consider imputation for features with <50% missing\n",
        "   - Drop or flag features with >50% missing\n",
        "\n",
        "2. **Feature Engineering:**\n",
        "   - Log transformation already applied to ACR and ALT\n",
        "   - Consider robust scaling (less sensitive to outliers)\n",
        "   - Feature interactions (age × BMI, etc.)\n",
        "\n",
        "3. **Outlier Handling:**\n",
        "   - Keep medically valid outliers\n",
        "   - Review and potentially remove outliers for: WBC, platelets, sodium, potassium\n",
        "   - Use robust scaling methods\n",
        "\n",
        "### 5.2 Model Training Considerations\n",
        "\n",
        "1. **Class Imbalance:**\n",
        "   - Use weighted loss functions for CVD prediction\n",
        "   - Consider oversampling/undersampling techniques\n",
        "   - Monitor precision-recall curves (not just accuracy)\n",
        "\n",
        "2. **Multi-Task Learning:**\n",
        "   - All 4 tasks share the same input features\n",
        "   - Missing targets handled via masking\n",
        "   - Consider task-specific loss weighting\n",
        "\n",
        "3. **Evaluation Metrics:**\n",
        "   - **CVD:** Accuracy, Precision, Recall, F1, ROC-AUC\n",
        "   - **Metabolic:** Per-label metrics + micro-averaged metrics\n",
        "   - **Kidney/Liver:** RMSE, MAE, R²\n",
        "\n",
        "### 5.3 Validation Strategy\n",
        "\n",
        "1. **Train/Test Split:**\n",
        "   - Already implemented in Transformation.py\n",
        "   - Ensure stratified split for CVD (maintain class balance)\n",
        "\n",
        "2. **Cross-Validation:**\n",
        "   - Consider k-fold CV for hyperparameter tuning\n",
        "   - Monitor all 4 tasks during validation\n",
        "\n",
        "3. **Early Stopping:**\n",
        "   - Monitor validation loss for all tasks\n",
        "   - Prevent overfitting on imbalanced classes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Summary for Project Discussion\n",
        "\n",
        "### Key Points to Highlight:\n",
        "\n",
        "1. **Dataset Size:** 56,893 records with 29 features\n",
        "2. **Multi-Task Learning:** 4 different prediction tasks (1 binary, 1 multi-label, 2 regression)\n",
        "3. **Data Quality:** Missing values handled via masking, outliers mostly medically valid\n",
        "4. **Clinical Relevance:** All features are clinically meaningful health markers\n",
        "5. **Challenges:** Class imbalance, missing data, multiple task types\n",
        "\n",
        "### Strengths:\n",
        "\n",
        "- Comprehensive health data from NHANES\n",
        "- Well-structured multi-task learning setup\n",
        "- Proper handling of missing values\n",
        "- Medical context considered in outlier analysis\n",
        "\n",
        "### Limitations:\n",
        "\n",
        "- High missing rates for some features\n",
        "- Class imbalance in CVD prediction\n",
        "- Missing data patterns need investigation\n",
        "- Some features have limited coverage\n",
        "\n",
        "### Next Steps:\n",
        "\n",
        "1. Train and evaluate the multi-task model\n",
        "2. Analyze feature importance for each task\n",
        "3. Compare single-task vs multi-task performance\n",
        "4. Interpret model predictions in clinical context\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
